{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-30T21:17:15.776179Z",
     "start_time": "2023-12-30T21:17:15.387087Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "os.chdir(\"/Users/aadityabhatia/Documents/GitHub/SE_Bugs_vs_Features\")\n",
    "\n",
    "# getting posts\n",
    "issues = pd.read_csv('data/issues.csv')\n",
    "len(issues) == 11074  # validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# gettign answers\n",
    "\n",
    "posts = pd.read_csv('data/data_main/posts.csv')\n",
    "answers = posts[posts.PostTypeId == 2]\n",
    "del posts\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T21:17:30.380266Z",
     "start_time": "2023-12-30T21:17:27.725469Z"
    }
   },
   "id": "dbcd9ee4137453ca"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# getting votes\n",
    "\n",
    "votes = pd.read_csv('data/data_main/votes.csv')\n",
    "votes = votes.rename(columns={'Id': 'VoteId',\n",
    "                              \"CreationDate\": \"VoteCreationDate\"})\n",
    "\n",
    "# Condense the votes into upvotes and downvotes for issues and answers\n",
    "votes = votes[(votes.VoteTypeId==2) | votes.VoteTypeId==3]\n",
    "votes['VoteType'] = votes['VoteTypeId'].apply(lambda x: 'upvote' if x == 2 else ('downvote' if x == 3 else 'other'))\n",
    "grouped_votes = votes.groupby(['PostId', 'VoteType']).size().unstack(fill_value=0).reset_index()\n",
    "\n",
    "del votes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T21:17:38.567428Z",
     "start_time": "2023-12-30T21:17:37.674728Z"
    }
   },
   "id": "e3ed5e1c9088cb54"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# getting comments\n",
    "\n",
    "comments = pd.read_csv('data/data_main/comments.csv')\n",
    "comments = comments.rename(columns={\"Text\": \"Text_Comment\",\n",
    "                                    \"UserId\": \"UserId_Comment\"})\n",
    "\n",
    "# grouping\n",
    "grouped_comments = comments.groupby('PostId')['Text_Comment'].apply(list).reset_index()\n",
    "grouped_commenters = comments.groupby('PostId')['UserId_Comment'].apply(list).reset_index()\n",
    "\n",
    "del comments\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T21:18:09.121362Z",
     "start_time": "2023-12-30T21:18:04.001851Z"
    }
   },
   "id": "9f931393ff4f9c32"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7f460f2d632107a"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "issues_with_votes_and_comments:\n",
      "Index(['Id', 'PostTypeId', 'CreationDate', 'Score', 'ViewCount', 'Body',\n",
      "       'OwnerUserId', 'LastEditorUserId', 'LastEditDate', 'LastActivityDate',\n",
      "       'Title', 'Tags', 'AnswerCount', 'CommentCount', 'ClosedDate',\n",
      "       'ContentLicense', 'PostId', 'Text_Comment', 'UserId_Comment'],\n",
      "      dtype='object')\n",
      "answers_with_votes_and_comments:\n",
      "Index(['Id', 'PostTypeId', 'AcceptedAnswerId', 'ParentId', 'CreationDate',\n",
      "       'DeletionDate', 'Score', 'ViewCount', 'Body', 'OwnerUserId',\n",
      "       'LastEditorUserId', 'LastEditDate', 'LastActivityDate', 'Title', 'Tags',\n",
      "       'AnswerCount', 'CommentCount', 'FavouriteCount', 'ClosedDate',\n",
      "       'ContentLicense', 'PostId', 'Text_Comment', 'UserId_Comment'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Merge comments and commenters with issues\n",
    "issues_with_comments = pd.merge(issues, grouped_comments, left_on='Id', right_on='PostId', how='left')\n",
    "issues_with_comments = pd.merge(issues_with_comments, grouped_commenters, on='PostId', how='left', suffixes=['_Comments', '_Commenters'])\n",
    "\n",
    "# Merge votes with issues\n",
    "issues_with_votes_and_comments = pd.merge(issues_with_comments, grouped_votes, on='PostId', how='left')\n",
    "\n",
    "# Merge comments and commenters with answers\n",
    "answers_with_comments = pd.merge(answers, grouped_comments, left_on='Id', right_on='PostId', how='left')\n",
    "answers_with_comments = pd.merge(answers_with_comments, grouped_commenters, on='PostId', how='left', suffixes=['_Comments', '_Commenters'])\n",
    "\n",
    "# Merge votes with answers\n",
    "answers_with_votes_and_comments = pd.merge(answers_with_comments, grouped_votes, on='PostId', how='left')\n",
    "\n",
    "# Ensure there's no duplicate PostId in the resulting dataframes\n",
    "issues_with_votes_and_comments = issues_with_votes_and_comments.drop_duplicates(subset='PostId')\n",
    "answers_with_votes_and_comments = answers_with_votes_and_comments.drop_duplicates(subset='PostId')\n",
    "\n",
    "# Display the structure of the dataframes\n",
    "print(f\"issues_with_votes_and_comments:\\n{issues_with_votes_and_comments.columns}\")\n",
    "print(f\"answers_with_votes_and_comments:\\n{answers_with_votes_and_comments.columns}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T21:19:47.286657Z",
     "start_time": "2023-12-30T21:19:47.088539Z"
    }
   },
   "id": "ee82b5cd78f54c3b"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "issue_cols = ['Id', 'CreationDate', 'Score', 'ViewCount', 'Body',\n",
    "       'OwnerUserId', 'Title', 'Tags', 'AnswerCount', 'CommentCount', \n",
    "       'Text_Comment', 'UserId_Comment']\n",
    "\n",
    "ans_cols = ['Id', 'ParentId', 'CreationDate',\n",
    "       'Score', 'ViewCount', 'Body', 'OwnerUserId',\n",
    "       'CommentCount', 'Text_Comment', 'UserId_Comment']\n",
    "\n",
    "\n",
    "issues_with_votes_and_comments = issues_with_votes_and_comments[issue_cols]\n",
    "answers_with_votes_and_comments = answers_with_votes_and_comments[ans_cols]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T21:23:10.055286Z",
     "start_time": "2023-12-30T21:23:10.028464Z"
    }
   },
   "id": "35809f34adf8075e"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# getting edits:\n",
    "\n",
    "edits = pd.read_csv('data/data_main/PostHistory.csv')\n",
    "\n",
    "# Assuming that the 'PostHistoryTypeId' indicates an edit and 'PostId' relates to the question's ID,\n",
    "# and we're interested in edits of the body (which might be represented by a specific 'PostHistoryTypeId'),\n",
    "# you might need to adjust the filtering condition based on your schema for 'PostHistoryTypeId' for edits.\n",
    "\n",
    "# Filter for edit entries (assuming PostHistoryTypeId for edits is either 4 for body edits or 5 for title edits)\n",
    "edits = edits[edits['PostHistoryTypeId'].isin([4, 5])]\n",
    "\n",
    "# Count the number of edits for each question\n",
    "question_edit_counts = edits.groupby('PostId')['Id'].count().reset_index(name='EditCount')\n",
    "\n",
    "# Get the unique list of editor IDs for each question\n",
    "question_editor_ids = edits.groupby('PostId')['UserId'].apply(lambda x: x.unique().tolist()).reset_index(\n",
    "    name='EditorIds')\n",
    "\n",
    "del edits\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T21:24:29.287952Z",
     "start_time": "2023-12-30T21:24:19.906569Z"
    }
   },
   "id": "a2d1e5533d28cf9b"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Combine the counts and the editor IDs into a single dataframe\n",
    "question_edits_info = pd.merge(question_edit_counts, question_editor_ids, on='PostId', how='left')\n",
    "\n",
    "# Merge this information with the issues dataframe\n",
    "issues_with_votes_comments_edits = pd.merge(issues_with_votes_and_comments, question_edits_info, left_on='Id', right_on='PostId', how='left')\n",
    "\n",
    "# Add a column for the number of unique editors\n",
    "issues_with_votes_comments_edits['num_ques_editors'] = issues_with_votes_comments_edits['EditorIds'].apply(\n",
    "    lambda x: len(x) if isinstance(x, list) else 0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T21:27:19.037509Z",
     "start_time": "2023-12-30T21:27:18.994495Z"
    }
   },
   "id": "f6cb22d74251c2c6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4405617aa8b965b"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 11354, cols: Index(['Id_Quens', 'CreationDate_Quens', 'Score_Quens', 'ViewCount_Quens',\n",
      "       'Body_Quens', 'OwnerUserId_Quens', 'Title', 'Tags', 'AnswerCount',\n",
      "       'CommentCount_Quens', 'Text_Comment_Quens', 'UserId_Comment_Quens',\n",
      "       'PostId', 'EditCount', 'EditorIds', 'num_ques_editors', 'Id_Answer',\n",
      "       'ParentId', 'CreationDate_Answer', 'Score_Answer', 'ViewCount_Answer',\n",
      "       'Body_Answer', 'OwnerUserId_Answer', 'CommentCount_Answer',\n",
      "       'Text_Comment_Answer', 'UserId_Comment_Answer'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Now, we merge the issues with answers. This will give us a table with issues and the corresponding answers\n",
    "issue_answers = pd.merge(issues_with_votes_comments_edits, answers_with_votes_and_comments, how='left', left_on=\"Id\",\n",
    "                         right_on=\"ParentId\", suffixes=[\"_Quens\", \"_Answer\"])\n",
    "\n",
    "# Then we can perform the next steps of feature generation on this merged dataframe\n",
    "print(f\"count: {len(issue_answers)}, cols: {issue_answers.columns}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T21:28:36.031209Z",
     "start_time": "2023-12-30T21:28:36.001700Z"
    }
   },
   "id": "65091b162899c1e"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# let go of the unwanted columns and save \n",
    "\n",
    "for col in ['PostId', \"ParentId\"]:\n",
    "    if col in issue_answers.columns:\n",
    "        del issue_answers[col]\n",
    "\n",
    "issue_answers.to_pickle(\"data/all_issue_data.pkl\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ad0f38cc275aebf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
